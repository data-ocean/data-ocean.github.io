<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<link rel="icon" href="/data-ocean.github.io/assets/images/logo.png">

<title>Text Classification (Part 3) | Data Ocean</title>

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Text Classification (Part 3) | Data Ocean</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Text Classification (Part 3)" />
<meta name="author" content="stephan" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fake News" />
<meta property="og:description" content="Fake News" />
<link rel="canonical" href="http://localhost:4000/data-ocean.github.io/text_classification_part_3/" />
<meta property="og:url" content="http://localhost:4000/data-ocean.github.io/text_classification_part_3/" />
<meta property="og:site_name" content="Data Ocean" />
<meta property="og:image" content="http://localhost:4000/data-ocean.github.io/assets/images/Newstand_part3.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-07T00:00:00-07:00" />
<script type="application/ld+json">
{"image":"http://localhost:4000/data-ocean.github.io/assets/images/Newstand_part3.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/data-ocean.github.io/text_classification_part_3/"},"url":"http://localhost:4000/data-ocean.github.io/text_classification_part_3/","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/data-ocean.github.io/assets/images/logo.jpeg"},"name":"stephan"},"author":{"@type":"Person","name":"stephan"},"headline":"Text Classification (Part 3)","description":"Fake News","datePublished":"2019-04-07T00:00:00-07:00","dateModified":"2019-04-07T00:00:00-07:00","@type":"BlogPosting","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

<link href="/data-ocean.github.io/assets/css/screen.css" rel="stylesheet">

<link href="/data-ocean.github.io/assets/css/main.css" rel="stylesheet">

<script src="/data-ocean.github.io/assets/js/jquery.min.js"></script>

<!-- mathjax config similar to math.stackexchange -->
<!-- <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script> -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>


</head>




<body class="layout-post">
	<!-- defer loading of font and font awesome -->
	<noscript id="deferred-styles">
		<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
	</noscript>


<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">

    <div class="container pr-0">

    <!-- Begin Logo -->
    <a class="navbar-brand" href="/data-ocean.github.io/">
    <img src="/data-ocean.github.io/assets/images/logo.jpeg" alt="Data Ocean">
    </a>
    <!-- End Logo -->

    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarMediumish">

        <!-- Begin Menu -->

            <ul class="navbar-nav ml-auto">

                
                <li class="nav-item">
                
                <a class="nav-link" href="/data-ocean.github.io/index.html">Blog</a>
                </li>

                <li class="nav-item">
                <a class="nav-link" href="/data-ocean.github.io/about">About</a>
                </li>
<!--
                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://bootstrapstarter.com/bootstrap-templates/template-mediumish-bootstrap-jekyll/"> Docs</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-wordpress/"><i class="fab fa-wordpress-simple"></i> WP Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.wowthemes.net/themes/mediumish-ghost/"><i class="fab fa-snapchat-ghost"></i> Ghost Version</a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/wowthemesnet/mediumish-theme-jekyll"><i class="fab fa-github"></i> Fork on Github</a>
                </li>
-->

                <script src="/data-ocean.github.io/assets/js/lunr.js"></script>


<style>
    .lunrsearchresult .title {color: #d9230f;}
    .lunrsearchresult .url {color: silver;}
    .lunrsearchresult a {display: block; color: #777;}
    .lunrsearchresult a:hover, .lunrsearchresult a:focus {text-decoration: none;}
    .lunrsearchresult a:hover .title {text-decoration: underline;}
</style>


<form class="bd-search" onSubmit="return lunr_search(document.getElementById('lunrsearch').value);">
    <input type="text" class="form-control text-small launch-modal-search" id="lunrsearch" name="q" maxlength="255" value="" placeholder="Type and enter..."/>
</form>

<div id="lunrsearchresults">
    <ul></ul>
</div>

<script src="/data-ocean.github.io/assets/js/lunrsearchengine.js"></script>

            </ul>

        <!-- End Menu -->

    </div>

    </div>
</nav>
<!-- End Navigation
================================================== -->

<div class="site-content">

<div class="container">

<!-- Site Title
================================================== -->
<div class="mainheading">
    <h1 class="sitetitle">Data Ocean</h1>
    <p class="lead">
        A discovery into the world of data.
    </p>
</div>

<!-- Content
================================================== -->
<div class="main-content">
    <!-- Begin Article
================================================== -->
<div class="container">
    <div class="row">

        <!-- Post Share -->
        <div class="col-md-2 pl-0">
            <div class="share sticky-top sticky-top-offset">
    <p>
        Share
    </p>
    <ul>
        <li class="ml-1 mr-1">
            <a target="_blank" href="https://twitter.com/intent/tweet?text=Text Classification (Part 3)&url=http://localhost:4000/data-ocean.github.io/text_classification_part_3/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://facebook.com/sharer.php?u=http://localhost:4000/data-ocean.github.io/text_classification_part_3/" onclick="window.open(this.href, 'facebook-share', 'width=550,height=435');return false;">
                <i class="fab fa-facebook-f"></i>
            </a>
        </li>

        <li class="ml-1 mr-1">
            <a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/data-ocean.github.io/text_classification_part_3/" onclick="window.open(this.href, 'width=550,height=435');return false;">
                <i class="fab fa-linkedin-in"></i>
            </a>
        </li>

    </ul>
    <!-- 
    <div class="sep">
    </div>
    <ul>
        <li>
        <a class="small smoothscroll" href="#disqus_thread"></a>
        </li>
    </ul>
     -->
</div>

        </div>

        <!-- Post -->
        

        <div class="col-md-9 flex-first flex-md-unordered">
            <div class="mainheading">

                <!-- Author Box -->
                
                <div class="row post-top-meta">
                    <div class="col-xs-12 col-md-3 col-lg-2 text-center text-md-left mb-4 mb-md-0">
                        
                        <img class="author-thumb" src="/data-ocean.github.io/assets/images/avatar.jpg" alt="Stephan">
                        
                    </div>
                    <div class="col-xs-12 col-md-9 col-lg-10 text-center text-md-left">
                        <a target="_blank" class="link-dark" href="https://data-ocean.github.io">Stephan</a><a target="_blank" href="https://twitter.com/sosterburg" class="btn follow">Follow</a>
                        <span class="author-description">Computer graphics veteran with 30+ years experience on the quest to discover the world of data.</span>
                    </div>
                </div>
                

                <!-- Post Title -->
                <h1 class="posttitle">Text Classification (Part 3)</h1>

            </div>

            <!-- Adsense if enabled from _config.yml (change your pub id and slot) -->
            
            <!-- End Adsense -->

            <!-- Post Featured Image -->
            

            
            <img class="featured-image img-fluid lazyimg" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAADklEQVR42mNkAANGCAUAACMAA2w/AMgAAAAASUVORK5CYII=" data-src="http://localhost:4000/data-ocean.github.io/assets/images/Newstand_part3.jpg" alt="Text Classification (Part 3)">
            

            
            <!-- End Featured Image -->

            <!-- Post Content -->
            <div class="article-post">
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <h2 id="using-big-data">Using Big Data</h2>

<p>The dataset used for that project is an already <a href="https://github.com/several27/FakeNewsCorpus">polished and fairly large corpus</a> by Maciej Szpakowski.</p>

<blockquote>
  <p>This is an open source dataset composed of millions of news articles mostly scraped from a curated list of 1001 domains from http://www.opensources.co/. Because the list does not contain any reliable websites, additionally NYTimes and Webhose English News Articles articles have been included to balance the classes better. The dataset is still work in progress, and for now, the public version includes only 9,408,908 articles (745 out of 1001 domains).</p>
</blockquote>

<p>The available data has more than 26GB on disk when we unzip the file and more than 75GB in RAM using pandas. For that reason, I considered using <a href="https://dask.org/">dask</a>. However, loading the CSV file ended in a ParserError (<code class="highlighter-rouge">Error tokenizing data. C error: EOF inside string starting at row 63</code>) and apparently, this is a <a href="https://stackoverflow.com/q/45752805/5983691">known problem</a> with dask’s read_csv if the file contains a newline character between quotes.</p>

<p>To read the CSV file with pandas, the same row (63) ended in a <code class="highlighter-rouge">_csv.Error: field larger than field limit (131072)</code>. To address that error we have to first increase the <code class="highlighter-rouge">csv.field_size_limit</code>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># _csv.Error: field larger than field limit (131072)
# https://stackoverflow.com/a/15063941/5983691
</span><span class="k">def</span> <span class="nf">csv_field_limit</span><span class="p">():</span>
    <span class="n">maxInt</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">maxsize</span>
    <span class="n">decrement</span> <span class="o">=</span> <span class="bp">True</span>

    <span class="k">while</span> <span class="n">decrement</span><span class="p">:</span>
        <span class="c1"># decrease the maxInt value by factor 10
</span>        <span class="c1"># as long as the OverflowError occurs.
</span>        <span class="n">decrement</span> <span class="o">=</span> <span class="bp">False</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">csv</span><span class="o">.</span><span class="n">field_size_limit</span><span class="p">(</span><span class="n">maxInt</span><span class="p">)</span>
        <span class="k">except</span> <span class="nb">OverflowError</span><span class="p">:</span>
            <span class="n">maxInt</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">maxInt</span><span class="o">/</span><span class="mi">10</span><span class="p">)</span>
            <span class="n">decrement</span> <span class="o">=</span> <span class="bp">True</span>
</code></pre></div></div>

<p>The dataset is not huge but is also larger than we’d like to manage on a laptop, especially if we value interactivity. In any case, let’s have a look at the first 100 rows to see what we have and determine what features we can drop and others we want to keep.</p>

<p><img src="/data-ocean.github.io/assets/images/BigDataTable.png" alt="Count Category" /></p>

<p>To fix the <code class="highlighter-rouge">EOF</code> problem, we can load in the dataset in chunks and loop that way through the dataset. Loading the CSV file in chunks helps but it is impractical to get a full picture of our data. With dask, we can utilise all the cores we have on our laptop.</p>

<p style="text-align: center;"><img src="/data-ocean.github.io/assets/images/DaskClient.png" alt="Content by URL Count" /></p>

<p>Now we can get a quick view of what categories and how many we have in our dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">categories</span> <span class="o">=</span> <span class="n">ddf</span><span class="o">.</span><span class="n">category</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="n">categories</span>
</code></pre></div></div>

<p style="text-align: center;"><img src="/data-ocean.github.io/assets/images/BigDataCategories.png" alt="Content by URL Count" /></p>

<p>As we can see we need to do some cleaning. We have some oddly named categories and I also checked for null values. From our data exploration, we have a few handy functions to clean the data we will use here again. For example, remove all digits, HTML strings and stopwords from our text and to lemmatise the words.</p>

<p>To send the data to separate processes for processing, we can configure dask’s scheduler and set it globally. This option is useful when operating on pure Python objects like strings.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="nb">set</span><span class="p">(</span><span class="n">scheduler</span><span class="o">=</span><span class="s">'processes'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="parquet">Parquet</h2>

<p>To save disk space dask encourages dataframes (pandas) users like us to use <a href="https://parquet.apache.org/">Parquet</a>. It is a columnar binary format that is easy to split into multiple files (easier for parallel loading) and is generally much simpler to deal with than compared to HDF5 a popular choice for Pandas users with high-performance needs. It is also a common format used by other big data systems like <a href="https://spark.apache.org/">Apache Spark</a> and <a href="https://impala.apache.org/">Apache Impala</a>.</p>

<p>For data-sets too big to fit conveniently into memory, like ours, we want to read it in line by line or iterate through the row-groups in a similar way to reading by chunks from CSV with pandas. For the latter, <a href="https://fastparquet.readthedocs.io/en">fastparquet</a> makes it possible to do that using <a href="https://fastparquet.readthedocs.io/en/latest/api.html#fastparquet.ParquetFile.iter_row_groups">iter_row_groups API</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pf</span> <span class="o">=</span> <span class="n">ParquetFile</span><span class="p">(</span><span class="s">'myfile.parq'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">pf</span><span class="o">.</span><span class="n">iter_row_groups</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1"># process sub-data-frame df
</span></code></pre></div></div>

<p>As an alternative option, I found the <a href="http://turicas.info/rows/">rows package</a> by  Álvaro Justen.</p>

<h2 id="deep-learning-model">Deep Learning Model</h2>

<p>For the initial model, I choose to create a Convolutional neural network (CNN)  using keras:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
	<span class="n">Conv1D</span><span class="p">(</span><span class="n">filters</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">input_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
		<span class="n">padding</span><span class="o">=</span><span class="s">'valid'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
	<span class="n">GlobalMaxPooling1D</span><span class="p">(),</span>
	<span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">),</span>
	<span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">),</span>
	<span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)</span>
	<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
</code></pre></div></div>

<p>Also, to be able to read in the data I needed to create a custom generator to process each line in the CSV file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_generator_process_line</span><span class="p">(</span><span class="n">line</span><span class="p">):</span>
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">()[:</span><span class="n">max_words</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">glove</span><span class="p">:</span>
            <span class="n">embedding</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">glove</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">Generator</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="c1"># skip header
</span>            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
                <span class="nb">next</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>

            <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">batch_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
            <span class="n">batch_category</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

            <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
                <span class="n">embedding</span><span class="p">,</span> <span class="n">category</span> <span class="o">=</span> <span class="n">_generator_process_line</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>

                <span class="k">if</span> <span class="p">(</span><span class="n">batch_i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_size</span><span class="p">:</span>
                    <span class="k">yield</span> <span class="n">batch_embedding</span><span class="p">,</span> <span class="n">batch_category</span>

                    <span class="n">batch_embedding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">max_words</span><span class="p">,</span> <span class="mi">100</span><span class="p">))</span>
                    <span class="n">batch_category</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                    <span class="n">batch_i</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_embedding</span><span class="p">[</span><span class="n">batch_i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding</span>
                    <span class="n">batch_category</span><span class="p">[</span><span class="n">batch_i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">category</span>
                    <span class="n">batch_i</span> <span class="o">+=</span> <span class="mi">1</span>
</code></pre></div></div>

<p>The following code snippet trains the model on data generated batch-by-batch by the python generator above on one GPU.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s">'/gpu:0'</span><span class="p">):</span>
	<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">Generator</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span>
					<span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">train_size</span><span class="o">//</span><span class="n">batch_size</span><span class="p">,</span>
					<span class="n">validation_data</span><span class="o">=</span><span class="n">Generator</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">),</span>
					<span class="n">validation_steps</span><span class="o">=</span><span class="n">valid_size</span><span class="o">//</span><span class="n">batch_size</span><span class="p">,</span>
					<span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>Our model returns a near perfect accuracy score of 97.83%, and if we are looking at the training and validation results, we might be inclined to save the keras model into a single HDF5 file at each epoch. That way we can save the best possible model. We probably could have stopped at the third epoch and saved us a lot of time.</p>

<p><img src="/data-ocean.github.io/assets/images/training_validation_results.png" alt="Content by URL Count" /></p>

<h2 id="gpu">GPU</h2>

<p>You may notice the <code class="highlighter-rouge">with</code>-statement and recall that I am working on a laptop. To train the model on the laptop is not manageable. To be able to train the model I used <a href="https://www.paperspace.com/gradient">paperspace’s</a> gradient service, which includes jupyter notebooks, a job runner, and a python module to run any code on Paperspace GPU cloud. The gradient machine I created is a Quadro P4000 with 8CPU’s and 30GB RAM. One epoch needed about 45 minutes to calculate.</p>

<h2 id="jupyter-notebook">Jupyter Notebook</h2>

<p>Here is the <a href="https://github.com/osterburg/dsc-5-capstone-project-online-ds-ft-100118/blob/master/03_data_collection.ipynb">notebook</a> to that post.</p>

<h2 id="what-next">What next?</h2>

<p>Create two more keras models, one which focuses on its “content” and the other model on its “context”. Furthermore, be able to predict what type of news article do we have - reliable or unreliable. And as a bonus, I like to add linguistic analysis.</p>

<p>Finally, build a <a href="https://dash.plot.ly/">dashboard</a>.</p>

            </div>

            <!-- Rating -->
            

            <!-- Post Date -->
            <p>
            <small>
                <span class="post-date"><time class="post-date" datetime="2019-04-07">07 Apr 2019</time></span>           
                
                </small>
            </p>

            <!-- Post Categories -->
            <div class="after-post-cats">
                <ul class="tags mb-4">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/categories#code">code</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/categories#content">content</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/categories#data">data</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Categories -->

            <!-- Post Tags -->
            <div class="after-post-tags">
                <ul class="tags">
                    
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/tags#deeplearning">#deeplearning</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/tags#fake">#fake</a>
                    </li>
                    
                    <li>
                        <a class="smoothscroll" href="/data-ocean.github.io/tags#news">#news</a>
                    </li>
                    
                </ul>
            </div>
            <!-- End Tags -->

            <!-- Prev/Next -->
            <div class="row PageNavigation d-flex justify-content-between font-weight-bold">
            
            <a class="prev d-block col-md-6" href="http://localhost:4000/data-ocean.github.io/text_classification_part_2/"> &laquo; Text Classification (Part 2)</a>
            
            
            <div class="clearfix"></div>
            </div>
            <!-- End Categories -->

        </div>
        <!-- End Post -->

    </div>
</div>
<!-- End Article
================================================== -->

<!-- Begin Comments
================================================== -->

    <div class="container">
        <div id="comments" class="row justify-content-center mb-5">
            <div class="col-md-8">
                <!-- <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = '';
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section> -->

            </div>
        </div>
    </div>

<!--End Comments
================================================== -->

<!-- Review with LD-JSON, adapt it for your needs if you like, but make sure you test the generated HTML source code first: 
https://search.google.com/structured-data/testing-tool/u/0/
================================================== -->

</div>



</div>

<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
            
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#data">data (9)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#code">code (9)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#map">map (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#Bayes">Bayes (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#beginner">beginner (2)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#forest">forest (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#art">art (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#deep-learning">deep learning (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#diffusion-maps">diffusion maps (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#papers">papers (1)</a>
                
                    <a class="mt-1 mb-1" href="/data-ocean.github.io/categories#content">content (3)</a>
                
            
            
		</div>
	</div>
</div>

<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                Copyright © 2019 Data Ocean
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">
                <a target="_blank" href="https://www.wowthemes.net/mediumish-free-jekyll-template/">Mediumish Jekyll Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

</div> <!-- /.site-content -->

<!-- Scripts
================================================== -->

<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js" integrity="sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut" crossorigin="anonymous"></script>

<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" crossorigin="anonymous"></script>

<script src="/data-ocean.github.io/assets/js/mediumish.js"></script>


<script src="/data-ocean.github.io/assets/js/lazyload.js"></script>


<script src="/data-ocean.github.io/assets/js/ie10-viewport-bug-workaround.js"></script>


<script id="dsq-count-scr" src="//.disqus.com/count.js"></script>


</body>
</html>
